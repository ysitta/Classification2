# Kuis Klasifikasi 2

Kuis ini merupakan bagian dari proses penilaian *Algoritma Academy*. Selamat anda sudah menyelesaikan materi *Classification in Machine Learning II*! Kami akan melakukan penilaian berupa kuis untuk menguji materi yang sudah dipelajari. Pengerjaan Kuis diharapkan dapat dilakukan di dalam kelas, silakan hubungi tim instruktur kami jika Anda melewatkan kesempatan untuk mengambilnya di kelas.

Dalam kuis ini, Anda akan menganalisis dataset *loan* (pinjaman bank) yang menyimpan *data historis nasabah bank yang cenderung default (gagal bayar pinjaman) atau tidak*. Data tersimpan dalam repositori ini sebagai `loan.csv`. Untuk menyelesaikan tugas ini, Anda perlu membuat model klasifikasi menggunakan algoritma Naive Bayes, Decision Tree, dan Random Forest dengan mengikuti langkah-langkah berikut: 

# Eksplorasi Data

Sebelum kita membuat model, kita akan coba memahami data terlebih dahulu. Muat data yang diberikan ke R (`loan.csv`) dan simpan ke dalam objek bernama` loan`, kemudian cek data secara singkat menggunakan fungsi `str()` atau `glimpse()`.

```{r}
# your code here

```

Berdasarkan investigasi di atas, data loan memiliki 1000 observasi dan 17 variabel. Berikut adalah deskripsi detail dari setiap kolom:

- `checking_balance` dan `savings_balance`: Status akun checking/savings yang ada
- `months_loan_duration`: Durasi periode pinjaman (dalam bulan)
- `credit_history`: Status kredit yang terdiri dari *critical* (kritis), *good* (baik), *perfect* (sempurna), *poor* (buruk), dan *very good* (sangat baik)
- `purpose`: Tujuan mengajukan pinjaman yang terdiri dari *business* (bisnis), *car(new)* (mobil baru), *car(used)* (mobil bekas), *education* (pendidikan), *furniture* (perabot rumah), dan *renovations* (renovasi)
- `amount`: Jumlah pinjaman dalam DM (Deutsche Mark)
- `employment_duration`: Durasi bekerja pada pekerjaan saat ini
- `percent_of_income`: Tingkat angsuran dalam persentase pendapatan bebas pajak
- `years_at_residence`: Durasi tinggal di alamat domisili saat ini (dalam tahun)
- `age`: Umur nasabah
- `other_credit`: Rencana cicilan lainnya (bank/store)
- `housing`: Kepemilikan rumah yang terdiri dari *rent* (sewa), *own* (milik sendiri), atau *for free* (gratis)
- `existing_loans_count`: Jumlah pinjaman yang sedang berjalan
- `job`: Pekerjaan yang terdiri dari *management* (manajemen), *skilled* (ahli), *unskilled* (tidak ahli) dan *unemployed* (pengangguran)
- `dependents`: Jumlah orang yang bertanggung jawab untuk melakukan pemeliharaan
- `phone`: Apakah terdaftar atas nama nasabah (antara *yes*/*no*)
- `default`: Apakah nasabah gagal bayar/*charged off*/lewat tanggal jatuh tempo (antara *yes*/*no*).

Kita juga perlu memastikan bahwa setiap kolom telah menyimpan tipe data yang tepat. Anda dapat melakukan data wrangling pada chunk di bawah ini bila dibutuhkan.

*Tips: Anda dapat menggunakan parameter `stringsAsFactors = TRUE` dari `read.csv()` sehingga semua kolom karakter akan otomatis disimpan sebagai faktor.* 

```{r}

```

Sebagai *data scientist*, Anda akan mengembangkan model yang dapat membantu manajemen dalam proses pengambilan keputusan. Hal pertama yang perlu kita ketahui adalah pertanyaan bisnis yang ingin kita pecahkan. Pinjaman adalah hal yang berisiko, namun pada saat yang sama juga menghasilkan keuntungan bagi lembaga melalui suku bunga pinjaman. **Mengidentifikasi nasabah yang berisiko tinggi untuk gagal bayar** adalah salah satu cara untuk meminimalisir kerugian pemberi pinjaman. Untuk itu, kita akan coba memprediksi kemungkinan nasabah gagal bayar menggunakan prediktor-prediktor yang disediakan.

Sebelum melakukan modeling, luangkan waktu Anda untuk melakukan langkah eksplorasi. Coba selidiki jumlah historis nasabah yang gagal bayar dari setiap tujuan pinjaman. Silakan lakukan agregasi data untuk mendapatkan jawabannya.

*Petunjuk: Karena kita hanya fokus pada nasabah yang default/gagal bayar, filter data historis dengan kondisi yang dibutuhkan (default == "yes")*

```{r}
# your code here

```

___
1. Berdasarkan eksplorasi di atas, pinjaman dari tujuan (*purpose*) apa yang paling sering gagal bayar?
  - [ ] Furniture/appliances
  - [ ] Car
  - [ ] Business
  - [ ] Education
___

# Cross-Validation

Sebelum kita membuat model, kita harus membagi dataset menjadi data train dan test. Silahkan bagi data dengan proporsi 80% train dan 20% test menggunakan fungsi `sample()`, `set.seed(100)`, dan simpan ke dalam obyek `data_train` dan `data_test`. 

> Note: Pastikan Anda menggunakan fungsi `RNGkind()` dan `set.seed()` sebelum membagi data dan menjalankannya bersamaan dengan code `sample()` Anda.

```{r}
RNGkind(sample.kind = "Rounding")
set.seed(100)
# your code here

```

Mari kita lihat proporsi kelas target pada data train menggunakan fungsi `prop.table (table(object$target))` untuk memastikan data train memiliki proporsi kelas target yang seimbang.

```{r}
# your code here

```

Berdasarkan proporsi di atas, dapat disimpulkan bahwa proporsi kelas target tidak seimbang; kita harus menyeimbangkannya sebelum menggunakannya pada model kita. Satu hal penting yang harus diingat adalah semua metode sub-sampling hanya boleh diterapkan pada data train. Lakukanlah metode *downsampling* pada `data_train` menggunakan fungsi `downSample()` dari package caret, lalu simpan data hasil downsample dalam objek `data_train_down`. Anda juga perlu memastikan bahwa variabel target sudah dalam tipe faktor. 

> Note: atur parameter `yname = "default"`

```{r}
library(caret)
set.seed(100)
# your code here
data_train_down <-

```

# Naive Bayes

Setelah membagi data menjadi data train dan test serta melakukan downsample pada data train, mari kita buat model pertama dengan algoritma Naive Bayes. Ada beberapa keuntungan dalam menggunakan model ini, misalnya:

- Modelnya relatif cepat untuk dilatih
- Dapat menghasilkan probabilitas bersyarat antara target dan prediktornya
- Dapat menangani fitur/variabel yang tidak relevan 

___
2. Berikut adalah karakteristik dari model Naive Bayes, **KECUALI**
  - [ ] Mengasumsikan hubungan antar prediktor yang saling independen
  - [ ] Mengasumsikan hubungan antara prediktor dan target variabel saling independen
  - [ ] Skewness due to data scarcity

*Referensi Opsi Bahasa Inggris:*
  - [ ] Assume that among the predictor variables are independent
  - [ ] Assume that between target and predictor variables are independent
  - [ ] Skewness due to data scarcity
___

Buat model Naive Bayes menggunakan fungsi `naiveBayes()` dari package `e1071`, lalu atur parameter `laplace = 1`. Simpan model ke dalam objek `model_naive` sebelum melanjutkan ke tahap berikutnya.

```{r}
library(e1071)
# your code here
model_naive <- 
```

# Prediksi Model Naive Bayes

Lakukan prediksi ke data test menggunakan `model_naive`. Gunakan fungsi `predict()` dengan parameter `type = "class"` untuk mendapatkan prediksi kelas. Simpan hasil prediksi ke dalam objek `pred_naive`. 

```{r}
# your code here
pred_naive <- 
```

# Evaluasi Model Naive Bayes

Bagian terakhir dari pembuatan model adalah evaluasi model. Anda dapat memeriksa performa model Naive Bayes menggunakan `confusionMatrix()` dan membandingkan kelas hasil prediksi (`pred_naive`) dengan label sebenarnya dari `data_test`. Pastikan Anda mengatur status pelanggan yang *default* sebagai kelas positif (`positive = "yes"`). 

```{r}
# your code here
```

# Decision Tree

Mari buat model Decision Tree menggunakan fungsi `ctree()` dan simpan ke dalam objek `model_dt`. Untuk melakukan *tuning* model, mari kita atur parameter `mincriterion = 0.90`.

```{r}
library(partykit)
set.seed(100)
# your code here
model_dt <-
```
___

3. Pada model decision tree, tujuan dari mengatur `mincriterion = 0.90` adalah ...
  - [ ] Untuk pemangkasan (*pruning*) pohon, hanya node dengan p-value <= 0.90 yang dapat melakukan *splitting node*
  - [ ] Untuk pemangkasan (*pruning*) pohon, hanya node dengan p-value <= 0.10 yang dapat melakukan *splitting node*
  - [ ] Untuk pemangkasan (*pruning*) pohon, hanya memperbolehkan pohon yang memiliki maksimum 10% data pada *terminal node*.

*Referensi Opsi Bahasa Inggris:*
  - [ ] To prune our model, we let the tree that has p-value <= 0.10 to split the node
  - [ ] To prune our model, we let the tree that has p-value <= 0.90 to split the node
  - [ ] To prune our model, we let the tree that has a maximum of 10% of the data in the terminal nodes

___

Untuk mendapatkan pemahaman yang lebih baik tentang model, buatlah plot dari model dan gunakan parameter `type = "simple"`.

```{r fig.width=12}
# your code here

```

4. Berdasarkan plot di atas, manakah pernyataan interpretasi di bawah ini yang **TEPAT**?
  - [ ] nasabah dengan `checking_balance` > 200 DM, dan `credit_history` tecatat "perfect", serta `saving_balance` yang "unknown" (tidak diketahui) diekspektasikan akan default
  - [ ] nasabah dengan `checking_balance` 1-200 DM, dan `months_loan_duration` < 21 diekspektasikan akan default
  - [ ] nasabah dengan `checking_balance` tercatat "unknown" (tidak diketahui), dan `other_credit` berupa "store" diekspektasikan akan default
  
*Referensi Opsi Bahasa Inggris:*
  - [ ] a customer who has `checking_balance` > 200 DM, with `credit_history` labelled "perfect", and `saving_balance` that is "unknown" is expected to default
  - [ ] a customer who has `checking_balance` 1-200 DM, with `months_loan_duration` < 21 is expected to default
  - [ ] a customer who has `checking_balance` that is "unknown", with `other_credit` consist of "store" is expected to default


# Prediksi Model Decision Tree

Setelah kita membuat model, coba lakukan prediksi ke data test berdasarkan `model_dt` menggunakan fungsi `predict()` dengan mengatur parameter `type = "response"`.

```{r}
# your code here
pred_dt <-
```

# Evaluasi Model Decision Tree

Untuk memeriksa performa model, kita dapat menggunakan `confusionMatrix()`. Pastikan Anda mengatur status pelanggan yang *default* sebagai kelas positif (`positive = "yes"`).  

```{r}
# your code here

```

# Random Forest

Model terakhir yang ingin kita buat adalah Randon Forest. Di bawah ini merupakan keunggulan dari model Random Forest:

- Automatic feature selection
- Mereduksi bias pada model karena melakukan aggregasi dari hasil beberapa decision tree
- Menghasilkan estimasi out-of-box error yang tidak bias

Sekarang, coba eksplorasi model random forest yang telah kami siapkan yaitu `model_rf.RDS`. Model tersebut dibuat menggunakan *hyperparameter* di bawah ini:

- `set.seed(100)` # angka seed
- `number = 5` # jumlah k-fold cross-validation
- `repeats = 3` # jumlah iterasi

Bacalah model Random Forest tersebut (`model_rf.RDS`)  menggunakan fungsi `readRDS()` dan simpan ke dalam objek `model_rf`.

```{r}
# your code here
model_rf <-
```

Kemudian, lihatlah rangkuman final model dari model Random Forest menggunakan `model_rf$finalModel`

```{r}
library(randomForest)
# your code here

```

Dalam praktiknya, random forest telah memiliki estimasi out-of-bag (OOB) yang merepresentasikan akurasi pada *out-of-bag data* (data yang tidak diambil ketika sampling/tidak digunakan dalam pembuatan random forest).

___
5. Berdasarkan ringkasan `model_rf$finalModel` di atas, bagaimana cara menginterpretasikan out-of-bag error dari model?
  - [ ] Kita memiliki error 33.61% pada *unseen data*
  - [ ] Kita memiliki error 33.61% pada data train
  - [ ] Kita memiliki error 33.61% pada data loan
  - [ ] Kita memiliki error 33.61% pada *in-sample data*

*Referensi Opsi Bahasa Inggris:*
  - [ ] We have 33.61% error of our unseen data
  - [ ] We have 33.61% error of our train data
  - [ ] We have 33.61% error of our loan data
  - [ ] We have 33.61% error of our in-sample data
___

Kita juga bisa menggunakan informasi *Variable Importance*, untuk mendapatkan daftar variabel penting yang digunakan pada model Random Forest. Banyak yang berargumen bahwa Random Forest, sebgai model *Black Box*, tidak dapat menawarkan informasi penting lain selain akurasinya yang amat tinggi. Namun, memberikan perhatian khusus pada atribut seperti *Variable Importance* sering kali membantu kita dalam mendapatkan informasi berharga tentang data.

Tentukan variabel yang memiliki pengaruh penting dalam menghasilkan prediksi (*Variable Importance*) menggunakan fungsi `varImp()`, kemudian masukkan ke dalam fungsi `plot()` untuk mendapatkan visualisasinya.

```{r}
# your code here

```

___
6. Dari plot yang terbentuk, variabel mana yang memiliki andil paling tinggi dalam menghasilkan prediksi?
  - [ ] checking_balance
  - [ ] months_loan_duration
  - [ ] amount
  - [ ] purpose
___ 

# Prediksi Model Random Forest
  
Setelah membangun model, kini kita dapat memprediksi data test menggunakan `model_rf`. Gunakan fungsi `predict()` dan atur parameter `type = "raw"` untuk mendapatkan prediksi kelas.

```{r}
# your code here
pred_rf <-
```

# Evaluasi Model Random Forest

Selanjutnya, mari kita evaluasi model random forest dengan fungsi `confusionMatrix()`.

```{r}
# your code here

```

Cara lain untuk mengevaluasi performa model adalah dengan melihat nilai ROC dan AUC-nya. Untuk menghitungnya, kita membutuhkan *probabilitas ke kelas positif untuk setiap observasi*. Mari fokus pada nilai ROC dan AUC dari prediksi model Random Forest. Pertama, lakukan prediksi ke data test menggunakan `model_rf` dengan menggunakan parameter `type = "prob"`. Akan dihasilkan prediksi nilai probabilitas untuk setiap kelas. Anda dapat menyimpan hasil prediksi ke dalam objek `prob_test`. 

```{r}
# your code here
prob_test <- 
```

Sekarang, gunakan fungsi `prediction()` dari package `ROCR` untuk membandingkan probability ke kelas positif yang tersimpan dalam `prob_test[,"yes"]` dengan data aktual `data_test$default`, kemudian simpan ke dalam objek `pred_roc`.

```{r}
library(ROCR)
# your code here
pred_roc <- 
```

Selanjutnya, gunakan fungsi `performance()` dari package ROCR dengan mendefinisikan axis plot untuk menghasilkan plot ROC. Simpan hasilnya ke dalam objek `perf`. Untuk menggunakan fungsi `performance()`, atur parameter di bawah ini:
  - `prediction.obj = pred_roc`
  - `measure = "tpr"`
  - `x.measure = "fpr"`

```{r}
# your code here
perf <-
```

Setelah Anda membuat objek `perf`, buatlah plot ROC dengan memasukkan objek `perf` ke dalam fungsi`plot()`.

```{r}
# your code here

```

Evaluasilah Kurva ROC; lihat apakah ada hasil yang tidak diinginkan dari model. Selanjutnya, carilah nilai AUC menggunakan fungsi `performance()` dengan mengatur parameter `prediction.obj = pred_roc` dan `measure = "auc"` lalu simpan ke dalam objek `auc`.

```{r}
# your code here
auc <- 
```

___
7. Dari hasil di atas, bagaimana Anda menginterpretasi nilai AUC?
  - [ ] 90.51% berarti performa model baik, nilai yang mendekati 1 semakin baik
  - [ ] 90.51% berarti performa model baik dalam mengklasifikasikan kelas postif
  - [ ] 95.11% berarti performa model baik dalam mengklasifikasikan kelas postif maupun kelas negatif
  - [ ] 95.11% sebagai *Area under ROC Curve* merepresentasikan akurasi model

*Referensi Opsi Bahasa Inggris:*
  - [ ] 90.51% means that the model performance is good because the closer to 1 the better
  - [ ] 90.51% means that the model performance is good in classifying positive classes
  - [ ] 95.11% means that the model performance is good in classifying both positive and negative class
  - [ ] 95.11% as Area under ROC Curve represent the accuracy of the model
___

# Komparasi Model

8. Sebagai seorang *data scientist* di sebuah institusi finansial, kita diminta untuk menghasilkan *rule-based model* yang dapat dengan mudah diimplementasikan pada sistem yang sudah ada. Model apa yang paling baik untuk digunakan?
  - [ ] Naive Bayes karena menghasilkan probabilitas bersyarat yang dihitung dengan baik
  - [ ] Decision Tree karena model mudah ditranslasikan menjadi suatu set aturan prediksi
  - [ ] Random Forest karena dapat dilakukan perunutan balik aturan prediksi berdasarkan informasi *variable importance*. 

*Referensi Opsi Bahasa Inggris:*
  - [ ] Naive Bayes because all the conditional probabilities are well calculated
  - [ ] Decision Tree because a decision tree model is easily translatable to a set of rules
  - [ ] Random Forest because it is possible to traceback the rule using variable importance information
  
9. Dari seluruh model yang telah dibuat, model mana yang memiliki performa paling baik dalam mengidentifikasi nasabah yang beresiko tinggi?
  - [ ] Naive Bayes
  - [ ] Decision Tree
  - [ ] Random Forest

Tujuan dari pembuatan model *machine learning* adalah untuk menggeneralisasi pola yang ada pada *data train* agar dapat menerapkannya pada data mana pun yang berasal dari domain (topik masalah) yang sama. Ini memungkinkan kita untuk membuat prediksi pada data baru yang belum pernah dilihat oleh model. Ada terminologi yang digunakan dalam *machine learning* ketika berbicara tentang seberapa baik model belajar dan kemampuannya dalam menggeneralisasi ke data baru, yaitu *overfitting* dan *underfitting*. 

Untuk memvalidasi apakah model kita cukup baik (*good fit*), kita dapat memprediksi ke data train dan test, lalu mengevaluasi performa model di kedua data tersebut. Kita dapat memeriksa apakah performanya seimbang (tidak jauh berbeda pada kedua data) berdasarkan batas toleransi yang telah kita tetapkan. 
___
10.  Berdasarkan pengetahuan Anda terkait karakteristik model machine learning, pernyataan manakah di bawah ini yang **SALAH**? 
  - [ ] Overfitting adalah kondisi dimana model baik dalam memprediksi data train, namun amat buruk dalam memprediksi data test.
  - [ ] Underfitting adalah kondisi dimana model buruk dalam memprediksi data train, namun baik dalam memprediksi data test.
  - [ ] Model Machine Learning yang baik mungkin memiliki performa yang sedikit lebih rendah pada data test dibandingkan pada data train. 
  
*Referensi Opsi Bahasa Inggris:*
  - [ ] Overfitting is a condition where a model performs well on the training data but performs very poorly in test data.
  - [ ] Underfitting is a condition where a model performs poor in the training data but performs well on the test data.
  - [ ] Machine Learning model that fit just right may have a slightly lower performance in its test data than in its training data.
___
